# -*- coding: utf-8 -*-
"""SériesTemporelles_LallementJulie

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VBNWoudNdGQJokF6hxJBBkQu2YOrIcPj

# Séries temporelles - Evaluation de Julie Lallement

## Exercice 1

Cette partie consiste à modéliser la production mensuelle de bière en Australie entre janvier 1956 et dévrier 1991, puis de la prédire sur 12 mois.

### Importation des bibliothèques et fonctions
"""

pip install pmdarima

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
import seaborn as sns
import plotly.offline
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
import statsmodels.api as sm
from statsmodels.tsa.stattools import pacf
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
import statsmodels.tsa.stattools as stattools
import pmdarima as pm
from pmdarima.arima import auto_arima
from pmdarima.arima import ADFTest
import math
from statsmodels.tsa.arima.model import ARIMA
import datetime

def test_stationarity(timeseries):
    #Determing rolling statistics
    MA = timeseries.rolling(window=12).mean()
    MSTD = timeseries.rolling(window=12).std()

    #Plot rolling statistics:
    plt.figure(figsize=(15,5))
    orig = plt.plot(timeseries, color='blue',label='Original')
    mean = plt.plot(MA, color='red', label='Rolling Mean')
    std = plt.plot(MSTD, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)

    #Perform Dickey-Fuller test:
    print('Results of Dickey-Fuller Test:')
    dftest = adfuller(timeseries, autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)

"""### Importation des données"""

df = pd.read_csv("/content/beer.txt", header = None)
df.head()

"""On voit qu'il n'y a pas de données sur la temporalité de la production, nous allons donc l'ajouter."""

# Ajout de la colonne de date en utilisant un offset de temps 'MS' pour mois début
df['date'] = pd.date_range(start='01-1956', periods=len(df), freq='MS')

# Définir la colonne 'date' comme index
df.set_index('date', inplace=True)

df.tail()

df = df.reset_index()

df.head()

#Insérer les olonnes année et mois afin de pouvoir observer s'il existe des sous-saisonnalité plus tard
df['date']= pd.DatetimeIndex(df['date'])
df['year'] = pd.DatetimeIndex(df['date']).year
df['month'] = pd.DatetimeIndex(df['date']).month

print(df)

df.describe()

"""Il y a 422 données dans le dataset "beer.txt" pour une seule variable, correspondant à la production de bière en Australie pendant les 35 années, nous ne connaissons pas l'unité. On peut voir que la moyenne est à 134.8 et la médiane à 137, il y aura donc peut-être un outlier vers une grosse production."""

df.info()

"""Il n'y a pas de valeurs manquantes, nous pouvons donc analyser ce dataset.

### Analyses
"""

#Définir les variables
df.columns = ['date', 'ProdBeer', 'year', 'month']
data = df['ProdBeer']
year = df['year']
month = df['month']
date = df['date']
df.head()

"""#### Test statistique de stationnarité

La stationnarité est un concept pour les séries temporelles où les paramètres statistiques comme la moyenne, la variance, etc. sont tous constants dans le temps.

Il existe plusieurs façons de détecter la saisonnalité dans une série temporelle en utilisant Python. L'une des méthodes les plus courantes consiste à utiliser des méthodes statistiques, comme le test de Dickey-Fuller ou le test de KPSS, pour vérifier si la série temporelle est stationnaire ou non. Si la série temporelle n'est pas stationnaire, il est probable qu'elle ait une saisonnalité.

Un exemple de test de Dickey-Fuller pour vérifier la stationnarité d'une série temporelle serait de tester l'hypothèse nulle H0: il existe une racine unitaire (c'est-à-dire que la série temporelle n'est pas stationnaire) contre l'hypothèse alternative H1: il n'y a pas de racine unitaire (c'est-à-dire que la série temporelle est stationnaire). On peut utiliser la statistique de test de Dickey-Fuller augmentée (ADF) pour effectuer ce test. Si la p-valeur associée à la statistique de test est inférieure à un seuil de signification prédéfini (généralement 0,05), on rejette l'hypothèse nulle et on conclut que la série temporelle est stationnaire. Sinon, on ne peut pas rejeter l'hypothèse nulle et on ne peut pas conclure que la série temporelle est stationnaire.
"""

# Test de Dickey-Fuller
result = stattools.adfuller(df["ProdBeer"])

# Résultats du test
print('Statistique de test : ', result[0])
print('p-valeur : ', result[1])
print('Nombre de lags : ', result[2])
print('Nombre de observations utilisées : ', result[3])
print('Critères d’arrêt : ', result[4])

# Interprétation des résultats
alpha = 0.05
if result[1] < alpha:
    print("On rejette l'hypothèse nulle, la série temporelle est stationnaire")
else:
    print("On ne peut pas rejeter l'hypothèse nulle, la série temporelle n'est pas stationnaire")

"""Ici, l'hypothèse nulle n'est pas rejetée, on ne peut pas conclure que la série temporelle est stationnaire au moins du point de vue de la racine unitaire (test d'ADF), nous allons donc pousser l'analyse.

#### Analyse de la stationnarité
"""

df.groupby(['year']).sum()['ProdBeer'].plot(figsize=(16,9), kind='bar', color = 'deeppink');

"""On peut voir que la production de bière augmentait de 1956 à environ 1976, pour ensuite être constante jusqu'en 1991, où elle chute mais cela est dû au fait que nous n'avons pas l'année entière de 1991. On voit donc une première partie d'augmentation de la production sur les années, puis une évolution constante, il y a donc une première tendance."""

plt.figure(figsize=(12,8))
plt.plot(df['date'], data, color='yellowgreen')
plt.title('Production de bière en Australie par mois')
plt.show()

"""On observe cette même tendance sur ce graphique, avec des courbes pouvant ressembler à de la saisonnalité, nous allons donc "zoomer" sur la temporalité."""

plt.figure(figsize=(12,8))
plt.plot(month, data, color='violet')
plt.title('Production de bière en Australie par mois')
plt.show()

"""On observe sur ce graphique qu'au moins numéro 6 (juin), la production de bière baisse quasiment toujours. On soupçonne donc un schéma qui se répète. Il y aurait moins de production en hiver, pour cela nous allons visualiser cette production par saison."""

plt.figure(figsize=(12,8))
# Ajouter une moyenne mobile pour visualiser la tendance
rolling_mean = df['ProdBeer'].rolling(window=12).mean()
plt.plot(year, rolling_mean)
plt.plot(year, data, color='hotpink')
plt.title('Production de bière en Australie par année')
plt.show()

"""Ici, on peut voir que la tendance positive est graduelle."""

#Définir les saisons ATTENTION ICI NOUS SOMMES EN AUSTRALIE
autumn = [3, 4, 5]
winter = [6, 7, 8]
spring = [9, 10, 11]
summer = [12, 1, 2]

# Ajouter une colonne pour la saison
df['season'] = None
df.loc[df['month'].isin(autumn),'season'] = 'Autumn'
df.loc[df['month'].isin(winter),'season'] = 'Winter'
df.loc[df['month'].isin(spring),'season'] = 'Spring'
df.loc[df['month'].isin(summer),'season'] = 'Summer'

df.head()

df.groupby(['season']).sum()['ProdBeer'].plot(figsize=(16,6), kind='bar', color = 'darkorchid', rot=0)
plt.xlabel("Saisons")
plt.ylabel("Production de Bière")
plt.title("Production de bière en fonction des saisons")

"""On confirme notre hypothèse de départ indiquant qu'il y a une baisse de production de bière en hiver en Australie, ainsi qu'une augmentation en été. Il y a donc une saisonnalité et une tendance. Nous allons effectuer des tests statistiques afin de confirmer cela.

"""

# Décomposer la série temporelle en ses composantes tendance, saisonnière et
#aléatoire, puis afficher les composantes saisonnières

seasonal = df.copy().set_index('date').sort_index()


analysis = seasonal[['ProdBeer']].copy()
analysis.sort_index(inplace=True)
decompose_result_mult = seasonal_decompose(analysis, model="multiplicative")

trend = decompose_result_mult.trend
seasonal = decompose_result_mult.seasonal
residual = decompose_result_mult.resid

fig = decompose_result_mult.plot();
fig.set_size_inches((14, 10))
fig.tight_layout()
plt.show()

"""Ici, nous avons décomposé automatiquement la série temporelle afin d'avoir une vue plus claire des composants.
On voit clairement une tendance vers le haut de 1956 à 1970 environ, nous tronquerons donc notre dataset à partir de 1970 pour effectuer notre modèle.
Nous voyons également un pattern de saisonnalité d'une durée d'un an, ainsi qu'une sous-saisonnalité.
Il est plus facile d'analyser la série si nous supprimons la saisonnalité de nos données, ce que nous allons faire.

### Stationnarisation

Pour rappel, le but de ce notebook est de prédire la production de bière dans les 12 mois. Comme cette production a une tendance avant 1970, nous la tronquerons à partir de cette date.
"""

df_filtre= df[df['date'] > pd.to_datetime('1970-01-01')]

"""Nous allons maintenant regarder la saisonnalité de ce dataset tronqué.

Les tests de stationnarité permettent de vérifier si une série est stationnaire ou non. Il y a deux types de test différents : les tests de stationnarité, comme le test KPSS, pour lesquels l'hypothèse nulle H0 est que la série est stationnaire , et les tests de racine unitaire comme le test de Dickey-Fuller, le test augmenté de Dickey-Fuller (ADF), ou encore le test de Phillips-Perron (PP) pour lesquels l'hypothèse nulle est que la série a été générée par un processus présentant une racine unitaire, et donc, qu'elle n'est pas stationnaire.
"""

# Test de Dickey-Fuller
result = stattools.adfuller(df_filtre["ProdBeer"])

# Résultats du test
print('Statistique de test : ', result[0])
print('p-valeur : ', result[1])
print('Nombre de lags : ', result[2])
print('Nombre de observations utilisées : ', result[3])
print('Critères d’arrêt : ', result[4])

# Interprétation des résultats
alpha = 0.05
if result[1] < alpha:
    print("On rejette l'hypothèse nulle, la série temporelle est stationnaire")
else:
    print("On ne peut pas rejeter l'hypothèse nulle, la série temporelle n'est pas stationnaire")

test_stationarity(df_filtre['ProdBeer'])

"""D'après les résultats du test de Dickey Fuller
Statistique du test : (-2.94) < Valeur critique (5%) : (-2.87).
Valeur p (0,05) < 0,05

Ici, le test d'ADF rejette l'hypothèse nulle que la série présente une racine unitaire et retient l'hypothèse alternative qu'elle est stationnaire. Mais seulement dans le sens de la racine unitaire.

Nous vérifierons la stationnarité avec un ACF, puisque c'est la méthode la plus efficace et que nous avons repéré une saisonnalité à l'oeil.
"""

df_filtre.head()

plt.figure(figsize=(12,8))
plt.plot(df_filtre['date'], df_filtre["ProdBeer"], color='yellowgreen')
plt.title('Production de bière en Australie par mois')
plt.show()

df_copy_acf = df_filtre.copy()
df_copy_acf  = df_copy_acf[['date', 'ProdBeer']]
df_copy_acf = df_copy_acf.set_index('date')
df_copy_acf

N = len(df_copy_acf)
m = 1
nlag_max = round(10*math.log10(N/m), 0)
nlag_max

plot_acf(df_copy_acf['ProdBeer'], ax=None, lags=nlag_max, alpha=0.05)
plt.show()

"""On voit qu'avec une ACF, notre série présente une saisonnalité car des comportements similaires sont observés de manière périodique.

On effectue une différenciation en « saisonnalité » si des
comportements similaires sont observés de manière
périodique. Par exemple, si ACF (12), ACF (24), . . .
sont proches de 1, on utilise une différenciation en
« saisonnalité » avec s = 12.
"""

fig, ax = plt.subplots(1,2,figsize=(20,5))
plot_acf(df_copy_acf['ProdBeer'], ax=ax[0], lags = 12)
plot_pacf(df_copy_acf['ProdBeer'], ax=ax[1], lags = 12)
plt.show()

def plot_acf_pacf(series, nlags):
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    sm.graphics.tsa.plot_acf(series, lags=nlags, ax = axes[0])
    axes[0].set_title('Sample ACF')

    sm.graphics.tsa.plot_pacf(series, lags=nlags, ax = axes[1])
    axes[1].set_title('Sample PACF')

    return fig

plot_acf_pacf(df_copy_acf.diff().dropna(), 12)

"""Avec une différenciation avec un lag de 12, la série devient stationnaire.

### Modèle SARIMA

Le modèle SARIMA est une extension du modèle ARIMA qui peut traiter les effets saisonniers des données.
Il a une sorte de 2 ordres (p,d,q) x (P,D,Q,M).
(p,d,q) est l'ordre qui est similaire à l'ordre du modèle ARIMA.
(P,D,Q,M) est connu comme l'ordre saisonnier où (P,D,Q) sont similaires aux (p,d,q) du modèle ARIMA. Nous effectuerons notre modèle avec une méthode empirique, que nous confirmerons avec un algorithme de recherche.

Nous allons tout d'abord diviser notre dataset en 2 parties : une partie train pour entraîner notre modèle, et une partie test pour le tester. Le 4 dernières années seront gardées en "test"
"""

split_date  = datetime.datetime.strptime('1988-01-01', '%Y-%m-%d')
df_train = df_copy_acf.loc[df_copy_acf.index < split_date]
df_test = df_copy_acf.loc[df_copy_acf.index >= split_date]

stepwise_model = auto_arima(df_train,
                            start_p=0,
                            start_q=0,
                            max_p=5,
                            max_d=5,
                            max_q=5,
                            start_P=1,
                            start_Q=1,
                            max_P=2,
                            max_D=2,
                            max_Q=2,
                            max_order=10,
                            m=12,
                            seasonal=True,
                            trace=True,
                            error_action='ignore',
                            suppress_warnings=True,
                            stepwise=True)
print(stepwise_model.aic())

"""Meilleur modèle:  ARIMA(0,1,1)(1,0,2)

"""

print(stepwise_model.summary())

plot_acf_pacf(stepwise_model.resid(), 12)

#Ici, j'utilise une autre méthode pour vérifier que je ne me suis pas trompée

model = sm.tsa.statespace.SARIMAX(df_train, trend='n', order=(0,1,1), seasonal_order=(1,0,2,12))
results = model.fit()
results.summary()

"""### Analyse des résidus

Le test de Ljung-Box est utilisé pour vérifier si les résidus d'un modèle statistique sont indépendants et ont une variance constante, ce qui est caractéristique d'un bruit blanc. Le test consiste à calculer la somme des carrés des résidus corrigés de moyenne pour des sous-séries de longueur croissante, et de les comparer à ce qui serait attendu si les résidus étaient réellement un bruit blanc. Si les résidus sont indépendants et ont une variance constante, ces sommes devraient être proches de ce qui est attendu pour un bruit blanc.

En général, on considère qu'un résultat inférieur à 0.05 indique que les résidus ne sont pas un bruit blanc et donc que le modèle n'est pas adapté.
 Ici on a 3.51 > 0.05, le résidu est donc un bruit blanc.
"""

residuals = pd.DataFrame(stepwise_model.resid())
residuals.plot(figsize=(20,5))
plt.show()

residuals.plot(kind='kde', figsize=(20,5))
plt.show()
print(residuals.describe())

"""D'après les graphiques des résidus, nous pouvons observer que le processus a une moyenne constante, centrée autour de zéro et une variance constante. De plus, graphiquement, il semble correspondre à une distribution normale.

Nous allons maintenant analyser de manière plus globale nos résultats :
"""

stepwise_model.plot_diagnostics(figsize=(15,9));

"""- L'histogramme de densité montre une distribution normale avec une moyenne proche de 0, comme indiqué précedemment,

- le graphique des résidus fluctuent également autour de 0

- dans le graphique "theoretical quantiles", nos points sont alignés avec la ligne rouge, indiiquant que la distribution n'est pas biaisée,

-  le corrélogramme des résidus indique qu'ils ne sont pas autocorrélés. Toutes les autocorrélations sont donc indiquées dans le modèle.

Le modèle semble être adapté, nous pouvons effectuer notre prédiction.

### Prévisions
"""

predictions = stepwise_model.predict(n_periods = 38, X=df_test)

predictions

predictions_df = predictions.to_frame()

predictions_df.columns = ['pred']

predictions_df.tail()

sarima_pred = stepwise_model.predict(n_periods = 38, X=df_test) # Il y a 38 mois à prédire

df_test["sarima_pred"] = sarima_pred
df_test

"""### Evaluation

Une analyse à posteriori permet de quantifier la différence entre les prévision et les réalisations. Nous utiliserons pour se faire le RMSE.
"""

mse = mean_squared_error(df_test['ProdBeer'], predictions_df['pred'])
mse

from math import sqrt

rmse = sqrt(mse)
rmse

df_test.describe()

"""Le RMSE (Root Mean Squared Error) est une métrique couramment utilisée pour évaluer la qualité des prévisions en séries temporelles. Il mesure la moyenne des erreurs au carré entre les valeurs prévues et les valeurs réelles, et est exprimé dans les mêmes unités que les données d'entrée.

Ici, nous avons un RMSE de 12.8, ce qui est en général considéré comme un bon résultat au vu de notre moyenne et écart-type. Cependant cela pourrait être amélioré.
"""

# Sélectionnez les 12 dernières prévisions de votre modèle
predictions_12 = predictions[-12:]

# Sélectionnez les 12 dernières valeurs réelles de votre série temporelle
y_test_12 = df_test['ProdBeer'][-12:]

# Calculez le MSE
mse12 = mean_squared_error(y_test_12, predictions_12)

mse12

rmse12 = sqrt(mse12)
rmse12

"""Le RMSE augmente lorsque l'on évalue la qualité prédictive de notre modèle sur les 12 derniers mois seulement. Il faudrait probablement revoir les paramètres de notre modèle, peut-être avec de la cross-validation, d'autres paramètres pour le modèle ou sinon un modèle plus efficace.

#Exercice 2

Cette partie consiste à prédire la concentration d'ozone à horizon d'un jour sur la ville de Rennes, avec un dataset du 01/04/1995 au 30/09/2002.

Il y a 24 variables  :


* (sans nom) : date (au format aaaammjj)
* maxO3 : teneur maximale en ozone observée sur la journée (en µ gr.m−3)
* T6, T9, T12, T15, T18 : température observée à 9h, 12h et 15h (en ◦C)
* Ne6, Ne9, Ne12, Ne15, Ne18 : nébulosité observée à 6h, 9h, 12h, 15h et 18h (en octas)
* Vdir6, Vdir9, Vdir12, Vdir15, Vdir18 : direction du vent observée à 6h, 9h, 12h,15h et 18h
* Vvit6, Vvit9, Vvit12, Vvit15, Vvit18 : vitesse du vent observée à 6h, 9h, 12h, 15h et 18h (en m.s−1)
* Vx : composante est-ouest du vent observée (en m.s−1)
* maxO3v : teneur maximale en ozone observée la veille (en µ gr.m−3)

##Importations des bibliothèques
"""

!pip install pystan~=2.14

pip install pmdarima

import sys

sys.version

pip install prophet

import plotly.express as px
from datetime import datetime, timedelta
from datetime import datetime
from sklearn.impute import KNNImputer
import calendar
from prophet import Prophet
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
import seaborn as sns
import plotly.offline
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
import statsmodels.api as sm
from statsmodels.tsa.stattools import pacf
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
import statsmodels.tsa.stattools as stattools
import pmdarima as pm
from pmdarima.arima import auto_arima
from pmdarima.arima import ADFTest
import math
from statsmodels.tsa.arima.model import ARIMA
import datetime
from math import sqrt
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV

"""##Importation du fichier"""

df2 = pd.read_csv('/content/ozone_complet.txt', sep=';')
df2.head()

"""Nous allons indiquer que l'index est la donnée temporelle."""

df2.index = pd.to_datetime(df2.index, format='%Y%m%d')
df2.tail()

"""Le dataset s'arrête bien à la date indiquée, nous avons effectué la bonne transformation."""

df2.describe()

"""À première vue, il semble ne pas y avoir de valeurs aberrantes, mais nous verrons cela lors de la partie exploratoire/descriptive."""

df2.info()

"""Nous observons qu'il y a des données manquantes pour maxO3,  max03v (ceci est normal), et les nébulosités observées. Dans l'énoncé, il nous est demandé de les éliminer, ce que nous allons faire, mais pas en les supprimant car nous sommes dans le cas d'une série temporelle. Nous les traiterons pendant l'analyse exploratoire."""

year = df2.index.year
month = df2.index.month

from datetime import datetime

date1 = "1995-04-01"
date2 = "2002-09-30"

# Convertir les chaînes de date en objets de date
date1_obj = datetime.strptime(date1, '%Y-%m-%d').date()
date2_obj = datetime.strptime(date2, '%Y-%m-%d').date()

# Utiliser la soustraction d'objets de date pour obtenir la différence en jours
delta = date2_obj - date1_obj

# Utiliser la propriété .days pour obtenir le nombre de jours
print(delta.days)

"""Nous remarquons également qu'il devrait y avoir 2739 observations journalières, nous en avons pourtant 1463 au maximum. Nous en déduisons que le dataset n'est pas complet.

##Gestion des valeurs manquantes
"""

plt.figure(figsize=(12,8))
plt.plot(df2['maxO3'], color='chartreuse')
plt.title('Teneur maximale en ozone observée sur la journée')
plt.show()

"""On s'aperçoit que les donnée manquantes sont regroupées entre elles (représentées ci-dessus par des traits distincts). Ces données manquantes se situent toujours au même moment des différentes années.

Nous allons commencer par calculer le pourcentage de valeurs manquantes dans chaque variable.
"""

missing_values = df2.isna().sum().to_dict()
print(missing_values)

"""Les valeurs manquantes sont donc majoritairement liées à la variable dépendante de notre modèle. Comme il s'agit d'une série temporelle, nous devons d'abord voir s'il y a une saisonnalité afin de savoir comment nous allons imputer ces valeurs manquantes."""

df2_2002 = df2[df2.index.year == 2002]

plt.plot(df2_2002['maxO3'], color='chartreuse')
plt.title('Teneur maximale en ozone observée sur la journée en 2002')
plt.show()

df2_2002_2001_2000 = df2[(df2.index.year == 2002) | (df2.index.year == 2001) | (df2.index.year == 2000) ]
plt.plot(df2_2002_2001_2000['maxO3'], color='mediumspringgreen')
plt.title('Teneur maximale en ozone observée sur la journée en 2002')
plt.show()

"""Sur 1 an, nous ne voyons pas de saisonnalité ou de tendances, ni même sur plusieurs années en "zoomant" un peu sur nos données. Par logique, nous supposons qu'il y en a par jour mais nous ne pouvons pas être plus précis que les données journalières.

Nous allons maintenant faire un traçage par saison, nous supposons qu'il y a davantage de production en hiver pour des questions de chauffage.
"""

import calendar
df2_spring = df2[df2.index.month.isin([3,4,5])]
df2_summer = df2[df2.index.month.isin([6,7,8])]
df2_fall = df2[df2.index.month.isin([9,10,11])]
df2_winter = df2[df2.index.month.isin([12,1,2])]

fig, ax = plt.subplots(2, 2, figsize=(20, 5))

ax[0,0].plot(df2_spring['maxO3'], color='pink')
ax[0,1].plot(df2_summer['maxO3'], color='tomato')
ax[1,0].plot(df2_fall['maxO3'], color='moccasin')
ax[1,1].plot(df2_winter['maxO3'], color='deepskyblue')
plt.suptitle('Teneur maximale en ozone observée sur la journée par saison')
plt.show()

"""Nous nous apercevons que les données temporelles qui sont ne sont pas disponibles dans la base de donnée correspondent à la saison **hivernale**. Mais ceci n'est pas très grave ici car nous cherchons à prédire la teneur en ozone à horizon d'un jour en automne. Il faudrait noter que notre modèle ne sera pas adapté pour prédire la teneur en ozone un jour d'hiver.

Pour les séries temporelles, les méthodes classiques d'imputation ne fonctionnent pas (médiane, moyenne, random etc).
On peut alors utiliser plusieurs techniques :
* '**ffill**' or 'pad' - Remplace les NaN s avec la dernière valeur observée
* '**bfill**' or 'backfill' - Remplace les NaN s avec la prochaine valeur observée
* **Linear interpolation method**

L'interpolation linéaire est une technique d'imputation qui suppose une relation linéaire entre les points de données et utilise les valeurs non manquantes des points de données adjacents pour calculer une valeur pour un point de données manquant.

Il existe également des techniques plus avancées :

* K-Nearest Neighbor Imputation : La classe KNNImputer permet d'imputer les valeurs manquantes à l'aide de l'approche des k-proches voisins.
* Multivariate feature imputation : Stratégie d'imputation des valeurs manquantes qui consiste à modéliser chaque caractéristique présentant des valeurs manquantes en fonction d'autres caractéristiques.

C'est ce que nous utiliserons pour maxO3 et maxO3v, les k-nearest neighbors.
"""

df2_copy = df2.copy(deep=True)

knn_imputer = KNNImputer(n_neighbors=10, weights="uniform")
df2_copy['maxO3'] = knn_imputer.fit_transform(df2_copy[['maxO3']])

df2_copy['maxO3'].isnull().sum()

"""Nous allons maintenant remplacer les valeurs manquantes de maxO3 par les valeurs de maxO3 de la veille."""

df2_copy['maxO3v'] = df2_copy['maxO3v'].fillna(df2_copy['maxO3'].shift(1))

"""Pour les autres variables où il y avait des valeurs manquantes, puisqu'il y en avait moins d'1%, nous pouvons utiliser la méthode de l'interpolation linéraire, car on les suppose linéraire."""

df2_copy['T6'].interpolate(method='linear', inplace=True)
df2_copy['T9'].interpolate(method='linear', inplace=True)
df2_copy['T12'].interpolate(method='linear', inplace=True)
df2_copy['T15'].interpolate(method='linear', inplace=True)
df2_copy['T18'].interpolate(method='linear', inplace=True)
df2_copy['Ne6'].interpolate(method='linear', inplace=True)
df2_copy['Ne9'].interpolate(method='linear', inplace=True)
df2_copy['Ne12'].interpolate(method='linear', inplace=True)
df2_copy['Ne15'].interpolate(method='linear', inplace=True)
df2_copy['Ne18'].interpolate(method='linear', inplace=True)
df2_copy['Vdir6'].interpolate(method='linear', inplace=True)
df2_copy['Vvit6'].interpolate(method='linear', inplace=True)
df2_copy['Vdir9'].interpolate(method='linear', inplace=True)
df2_copy['Vvit9'].interpolate(method='linear', inplace=True)
df2_copy['Vdir12'].interpolate(method='linear', inplace=True)
df2_copy['Vvit12'].interpolate(method='linear', inplace=True)
df2_copy['Vdir15'].interpolate(method='linear', inplace=True)
df2_copy['Vvit15'].interpolate(method='linear', inplace=True)
df2_copy['Vdir18'].interpolate(method='linear', inplace=True)
df2_copy['Vvit18'].interpolate(method='linear', inplace=True)
df2_copy['Vx'].interpolate(method='linear', inplace=True)

missing_values_copy = df2_copy.isna().sum().to_dict()
print(missing_values_copy)

"""Il n'y a plus de valeurs manquantes. Nous pouvons commencer à regarder si la série temporelle est stationnaire, même si on le suppose."""

df2_copy['day_of_week'] = df2_copy.index.day_name()

df2_copy.groupby(['day_of_week']).sum()['maxO3'].plot(figsize=(16,6), kind='bar', color = 'darkorchid', rot=0)
plt.xlabel("Weekday")
plt.ylabel("Teneur en ozone")
plt.title("Teneur maximale en ozone observée sur la journée par jour de la semaine")

"""Même selon les jours de la semaine, nous n'observons pas de différences flagrantes.

## Analyse de la stationnarité
"""

df2_acf = df2_copy.copy()
df2_acf  = df2_acf[['maxO3']]
df2_acf.index.names = ['Date']
df2_acf

# Test de Dickey-Fuller
result_df2 = stattools.adfuller(df2_acf["maxO3"])

# Résultats du test
print('Statistique de test : ', result_df2[0])
print('p-valeur : ', result_df2[1])
print('Nombre de lags : ', result_df2[2])
print('Nombre de observations utilisées : ', result_df2[3])
print('Critères d’arrêt : ', result_df2[4])

# Interprétation des résultats
alpha = 0.05
if result_df2[1] < alpha:
    print("On rejette l'hypothèse nulle, la série temporelle est stationnaire")
else:
    print("On ne peut pas rejeter l'hypothèse nulle, la série temporelle n'est pas stationnaire")

"""Ici, le test d'ADF rejette l'hypothèse nulle que la série présente une racine unitaire et retient l'hypothèse alternative qu'elle est stationnaire. Mais seulement dans le sens de la racine unitaire.
Nous allons maintenant analyser la stationnarité avec l'ACF.
"""

N = len(df2_acf)
m = 1
nlag_max = round(10*math.log10(N/m), 0)
nlag_max

fig, ax = plt.subplots()
sm.graphics.tsa.plot_acf(df2_acf['maxO3'], lags=nlag_max, ax=ax)
plt.show()

def plot_acf_pacf(series, nlags):
    fig, axes = plt.subplots(1, 2, figsize=(20, 8))

    sm.graphics.tsa.plot_acf(series, lags=nlags, ax = axes[0])
    axes[0].set_title('Sample ACF')

    sm.graphics.tsa.plot_pacf(series, lags=nlags, ax = axes[1])
    axes[1].set_title('Sample PACF')

    return fig

fig = plot_acf_pacf(df2_acf, nlags= nlag_max)
plt.show(fig)

"""On observe que le graphique de l'ACF qu'elle décroît rapidement vers 0 en sinusoïdale amortie, cela indique qu'elle est stationnaire, de plus la PACF est considérée comme nulle. Ce dernier graphique nous suggère un **ARMA(1,0)** car on observe une forte autocorrélation au lag 1, et ensuite nulle.
L'autocorréloggrame simple est nul après le lag 6, ce qui suggère un modèle **ARMA(0,6)**.

## Modèles sans pic d'ozone de la veille

Dans cette sous-partie nous allons explorer différents modèles en ne prenant pas en compte la variable maxO3v.
"""

split_date  =datetime.strptime('2002-01-01', '%Y-%m-%d')
df2meteo = df2_copy.drop('maxO3v', axis = 1)
df2meteo_train = df2meteo.loc[df2meteo.index < split_date]
df2meteo_test = df2meteo.loc[df2meteo.index >= split_date]

df2meteo_test

"""### Modèle 1 : Prophet

Le modèle Prophet attends que le dataset soit paramétré de manière spécifique. Nous allons donc renommer nos colonnes.
"""

df2meteo_train_prophet = df2meteo_train.assign(ds=df2meteo_train.index)
df2meteo_train_prophet = df2meteo_train_prophet.reset_index(drop=True)

df2meteo_test_prophet = df2meteo_test.assign(ds=df2meteo_test.index)
df2meteo_test_prophet = df2meteo_test_prophet.reset_index(drop=True)

df2meteo_train_prophet

df2meteo_train_prophet = df2meteo_train_prophet.rename(columns={'maxO3': 'y'})

df2meteo_test_prophet = df2meteo_test_prophet.rename(columns={'maxO3': 'y'})

# Modèle d'entrainement puis on le fit
modelmeteo = Prophet()
modelmeteo.fit(df2meteo_train_prophet.reset_index() \
              .rename(columns={'Datetime':'ds',
                               'PJME_MW':'y'}))

# Prédiction sur le set train
df2meteo_test_fcst = modelmeteo.predict(df=df2meteo_test_prophet.reset_index() \
                                   .rename(columns={'Datetime':'ds'}))

# Tracer les prévisions
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
fig = modelmeteo.plot(df2meteo_test_fcst,
                 ax=ax)
plt.show()

# Plot les prévisions avec la réalité
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(df2meteo_test.index, df2meteo_test_prophet['y'], color='r')
fig = modelmeteo.plot(df2meteo_test_fcst, ax=ax)

df2meteo_test_fcst.head()

msemeteo_prophet = mean_squared_error(y_true=df2meteo_test_prophet['y'],
                   y_pred=df2meteo_test_fcst['yhat'])
msemeteo_prophet

from math import sqrt

rmsemeteo_prophet = sqrt(msemeteo_prophet)
rmsemeteo_prophet

"""### Modèle 2 : XGBOOST"""

df2meteo_train = df2meteo_train.drop("day_of_week", axis = 1)
df2meteo_test = df2meteo_test.drop("day_of_week", axis = 1)

df2meteo_test

X_train = df2meteo_train.drop('maxO3', axis=1)
y_train = df2meteo_train['maxO3']

X_test = df2meteo_test.drop('maxO3', axis=1)
y_test = df2meteo_test['maxO3']

Y = df2meteo['maxO3']

from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier


# encode string class values as integers
label_encoder = LabelEncoder()
label_encoder = label_encoder.fit(Y)
label_encoded_y_train = label_encoder.transform(y_train)

param_grid = {'max_depth':[1, 2], 'gamma':[0, 0.5, 1], 'n_estimators':[100, 200], 'learning_rate':[0.05, 0.1]}

optimal_params = GridSearchCV(
        XGBClassifier(seed='12345'),
        param_grid,
        cv=5,
        verbose=2 # NOTE: If you want to see what Grid Search is doing, set verbose=2
    )

optimal_params.fit(X_train,label_encoded_y_train)
print(optimal_params.best_params_)

"""Nous n'utiliserons pas la cross-validation pour choisir nos paramètres car les paramètres testés ci-dessous n'ont pas eu un résultat concluant par rapport aux modèles finetuné à la main, il faudrait pouvoir utiliser la crossvalidation avec davantages de paramètres cependant cela s'avèrerait très chronophage pour le peu que cela nous apporterait (ici la CV a tourné pendant 1h30)."""

#{'gamma': 1, 'learning_rate': 0.05, 'max_depth': 1, 'n_estimators': 100}

import time
ts = time.time()

model = XGBRegressor(max_depth= 4, gamma= 15, n_estimators=1000, learning_rate=0.1, random_state=42)

model.fit(
    X_train,
    y_train,
    eval_metric="rmse",
    eval_set=[(X_train, y_train), (X_test, y_test)],
    verbose=True,
    early_stopping_rounds = 100)

time.time() - ts

#predicting validation data.
predmeteo=model.predict(X_test)

# Calculate the MSE
msemeteo_xgboost = mean_squared_error(y_test, predmeteo)

# Print the MSE
print("MSE: ", msemeteo_xgboost)

rmsemeteo_xgboost = sqrt(msemeteo_xgboost)
rmsemeteo_xgboost

# Sélection de la dernière prévision du modèle
predictionsmeteo_1 = predmeteo[-1:]
predictionsmeteo_1

# Sélection de la dernière valeur réelle de votre série temporelle
y_testmeteo_1 = y_test[-1:]

# Calcul du MSE
msemeteo_1 = mean_squared_error(y_testmeteo_1, predictionsmeteo_1)
msemeteo_1

rmsemeteo_xgboost_1 = sqrt(msemeteo_1)
rmsemeteo_xgboost_1

"""Ici, le RMSE pour la prévision du taux d'ozone à horizon d'un jour est de 1.89,"""

f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(y_test.index, y_test, color='r')
ax.plot(y_test.index, predmeteo, color='b')
ax.set_xlabel('Index')
ax.set_ylabel('Value')
ax.set_title('XGBoost Predictions vs Actual Values')
plt.show()

"""Le modèle XGBoost sur les données sans le pic d'ozone a tendance a surestimé le taux d'ozone prédit, cependant dans l'ensemble, elles sont cohérentes.

## Modèles avec pic d'ozone de la veille

Nous allons effectué notre prédiction avec un modèle ARMA.
"""

split_date = datetime.strptime('2002-01-01', '%Y-%m-%d')
df2_train = df2_copy.loc[df2_copy.index < split_date]
df2_test = df2_copy.loc[df2_copy.index >= split_date]

df2_test

"""### Modèle 1 : Prophet

Le modèle Prophet attends que le dataset soit paramétré de manière spécifique. Nous allons donc renommer nos colonnes.
"""

df2_train_prophet = df2_train.assign(ds=df2_train.index)
df2_train_prophet = df2_train_prophet.reset_index(drop=True)

df2_test_prophet = df2_test.assign(ds=df2_test.index)
df2_test_prophet = df2_test_prophet.reset_index(drop=True)

df2_train_prophet

df2_train_prophet = df2_train_prophet.rename(columns={'maxO3': 'y'})

df2_test_prophet = df2_test_prophet.rename(columns={'maxO3': 'y'})

df2_train_prophet

# Modèle d'entrainement puis on le fit
model = Prophet()
model.fit(df2_train_prophet.reset_index() \
              .rename(columns={'Datetime':'ds',
                               'PJME_MW':'y'}))

# Predict on training set with model
df2_test_fcst = model.predict(df=df2_test_prophet.reset_index() \
                                   .rename(columns={'Datetime':'ds'}))

# Tracer les prévisions
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
fig = model.plot(df2_test_fcst,
                 ax=ax)
plt.show()

# Plot the components of the model
fig = model.plot_components(df2_test_fcst)

# Plot the forecast with the actuals
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(df2_test.index, df2_test_prophet['y'], color='r')
fig = model.plot(df2_test_fcst, ax=ax)

df2_test_fcst.head()

mse_prophet = mean_squared_error(y_true=df2_test_prophet['y'],
                   y_pred=df2_test_fcst['yhat'])
mse_prophet

from math import sqrt

rmse_prophet = sqrt(mse_prophet)
rmse_prophet

"""Nous comparerons ce score avec celui d'autres modèles.

### Modèle 2 : XGBOOST
"""

df2_train = df2_train.drop("day_of_week", axis = 1)
df2_test = df2_test.drop("day_of_week", axis = 1)

X_train_avec = df2_train.drop('maxO3', axis=1)
y_train_avec = df2_train['maxO3']

X_test_avec = df2_test.drop('maxO3', axis=1)
y_test_avec = df2_test['maxO3']

import time
ts = time.time()

modelXG = XGBRegressor(max_depth= 4, gamma= 15, n_estimators=1000, learning_rate=0.1, random_state=42)

modelXG.fit(
    X_train_avec,
    y_train_avec,
    eval_metric="rmse",
    eval_set=[(X_train_avec, y_train_avec), (X_test_avec, y_test_avec)],
    verbose=True,
    early_stopping_rounds = 100)

time.time() - ts

#predicting validation data.
predxg=modelXG.predict(X_test_avec)

# Calcul du MSE et RMSE
mse_xgboost = mean_squared_error(y_test_avec, predxg)
rmse_xgboost = sqrt(mse_xgboost)

print("MSE: ", mse_xgboost)
print("RMSE: ", rmse_xgboost)

# Sélection de la dernière prévision du modèle
predxg_1 = predxg[-1:]

# Sélection de la dernière valeur réelle de la série temporelle
y_test_1 = y_test_avec[-1:]

# Calcul le MSE
mse_1 = mean_squared_error(y_test_1, predxg_1)

#Calcul du RMSE
rmse_xgboost_1 = sqrt(mse_1)
print("MSE: ", mse_1)
print("RMSE: ", rmse_xgboost_1)

f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(y_test_avec.index, y_test_avec, color='r')
ax.plot(y_test_avec.index, predxg, color='b')
ax.set_xlabel('Index')
ax.set_ylabel('Value')
ax.set_title('XGBoost Predictions vs Actual Values')
plt.show()

"""Le modèle XGBoost sur les données avec le pic d'ozone a tendance a surestimé le taux d'ozone prédit, cependant dans l'ensemble, elles sont cohérentes.

## Analyse des bruits blancs

Il nous fallait d'abord déterminer quel était le modèle le plus efficace afin d'ensuite analyser ses résidus, même si ce n'est pas dans ce sens que l'on fait habituellement.
"""

residuals_xg = y_test_avec - predxg

from statsmodels.stats.diagnostic import acorr_ljungbox

_, p_value = acorr_ljungbox(residuals_xg, boxpierce=False)

plt.figure(figsize=(15,9))
plt.plot(residuals_xg)
plt.title("Résidus du modèle XGboost sans pic d'ozone de la veille")
plt.xlabel("Index")
plt.ylabel("Résidus")
plt.show()

"""Les résidus sont aléatoires, ce qui indique généralement un bon modèle de prédiction.

Ici, nous allons effectuer un test de Shapiro-Walk. Si la p-value est inférieure au seuil 0,05, on peut rejeter l'hypothèse d'une distribution normale pour les données.
"""

from scipy.stats import shapiro

stat, p = shapiro(residuals_xg)
print("Test statistique : ", stat)
print("p-value : ", p)

"""On peut voir que la p-value est supérieure à 0.05 (0.1), la distribution des résidus  du modèle XGboost sans pic d'ozone de la veille n'est donc pas normale."""

residuals_xg.plot(kind='kde', figsize=(20,5))
plt.show()
print(residuals_xg.describe())

"""D'après le graphiques des résidus, nous pouvons observer que le processus a une moyenne centrée autour de 4 et une variance constante. Cela signifie que la différence entre les valeurs réelles et les valeurs prévues par le modèle de série temporelle est en moyenne de 4. Cela peut indiquer que le modèle n'est pas entièrement approprié pour la série temporelle Ozone et que des ajustements supplémentaires doivent être effectués pour améliorer la qualité des prévisions.

On se rend compte que la série n'est pas stationnaire, il faut la différencier, ce que nous n'avions pas vu avec l'ACP. Même si la courbe décroissais rapidement vers 0, nous n'avions pas remarqué les légères oscillations.

## Stationnarisation
"""

#Notre ancien ACP
fig, ax = plt.subplots()
sm.graphics.tsa.plot_acf(df2_acf['maxO3'], lags=nlag_max, ax=ax)
plt.show()

"""Nous allons différencier notre série une fois afin de voir si cette dernière devient stationnaire."""

df2_new = df2_copy.drop("day_of_week", axis = 1)

df2_new.index = pd.to_datetime(df2_new.index)

diff_df2 = df2_new.diff()

diff_df2 = diff_df2.dropna()

from statsmodels.graphics.tsaplots import plot_pacf
import matplotlib.pyplot as plt

# tracer l'ACP de diff_df2
fig, ax = plt.subplots(figsize=(12,5))
plot_acf(diff_df2['maxO3'], ax=ax, lags=12)
ax.set_xlabel('Lag')
ax.set_ylabel('Partial Autocorrelation')
ax.set_title('Partial Autocorrelation of diff_df2')
plt.show()

"""On voit ici que L'ACP est une sinusoîdale amortie, la série est maintenant stationnaire.

## Modèle de régression linéaire avec ozone de la veille

Dans l'énoncé, il nous faut proposer un modèle de régression, nous choisissons un modèle de régression linéaire.
"""

split_date  = datetime.strptime('2002-01-01', '%Y-%m-%d')
df_train = diff_df2.loc[diff_df2.index < split_date]
df_test = diff_df2.loc[diff_df2.index >= split_date]

X_train = df_train.drop(df_train.columns[0], axis=1)
y_train = df_train.iloc[:, 0]

X_test = df_test.drop(df_test.columns[0], axis=1)
y_test = df_test.iloc[:, 0]

from sklearn.linear_model import LinearRegression
LR = LinearRegression()

LR.fit(X_train, y_train)

pred = LR.predict(X_test)

print("RMSE: ", np.sqrt(mean_squared_error(pred, y_test)))

# Sélection de la dernière prévision du modèle
pred_1 = pred[-1:]

# Sélection de la dernière valeur réelle de la série temporelle
y_test_1 = y_test[-1:]

print("RMSE: ", np.sqrt(mean_squared_error(pred_1, y_test_1)))

"""Le RMSE à horizon d'un jour avec un modèle de régression linéaire comprenant les données de la veille est de 7,29, et de 13, 71 sur la globalité des prédictions.

Ici, nous allons effectuer un test de Shapiro-Walk. Si la p-value est inférieure au seuil 0,05, on peut rejeter l'hypothèse d'une distribution normale pour les données.
"""

from scipy.stats import shapiro

residuals = y_test - pred

stat, p = shapiro(residuals)
print("Test statistique : ", stat)
print("p-value : ", p)

"""Ici la p-value est de 0.057, nous allons rester souple et admettre que la distribution est normale, davantage au seuil des 10%.

## Modèle de régression linéaire sans ozone de la veille
"""

X_train = df_train.drop(["maxO3", "maxO3v"], axis=1)
y_train = df_train.iloc[:, 0]

X_test = df_test.drop(["maxO3", "maxO3v"], axis=1)
y_test = df_test.iloc[:, 0]

LR = LinearRegression()

LR.fit(X_train, y_train)

pred = LR.predict(X_test)

print("RMSE: ", np.sqrt(mean_squared_error(pred, y_test)))

# Sélection de la dernière prévision du modèle
pred_1_2 = pred[-1:]

# Sélection de la dernière valeur réelle de la série temporelle
y_test_1_2 = y_test[-1:]

print("RMSE: ", np.sqrt(mean_squared_error(pred_1_2, y_test_1_2)))

"""Le RMSE à horizon d'un jour avec un modèle de régression linéaire comprenant les données de la veille est de 7,45, et de 13,87 sur la globalité des prédictions."""

from scipy.stats import shapiro

residuals = y_test - pred

stat, p = shapiro(residuals)
print("Test statistique : ", stat)
print("p-value : ", p)

"""Sans les données d'ozone de la veille, les résidus ne sont plus des bruits blancs selon le test de Shapiro-Walk.

## Conclusion

J'ai tout de suite tenté les modèles XGBoost car ce sont ceux les plus efficaces, cependant j'ai par la suite testé avec un modèle de régression linéaire simple quand j'ai vu que les résidus n'étaient pas des bruits blancs. Il fallait en effet les différencier pour avoir de bons résultats.

On voit que le RMSE du modèle XGBOOST avec les données de pic d'ozone de la veille est plus performant que celui sans les données du pic d'ozone de la veille pour tout le set de test (RMSE de 11.90 contre 14.3), mais pas à horizon d'un jour (RMSE de 2.01 contre 1.89). Il se peut que les données du pic d'ozone de la veille ne soient pas aussi pertinentes pour les prévisions à court terme, et au contraire influence trop les résultats sans prendre en compte les autres paramètres, pour ce modèle du moins.

Pour les modèles de régression linéaire, celui sans les données de la veille est non seulement moins performant du côté prédictif, mais les résidus ne sont pas des bruits blancs.
Le modèle avec les données de la veille a pour résidus des bruits blancs, et a de bonnes capacités prédictives (le RMSE à horizon d'un jour avec un modèle de régression linéaire comprenant les données de la veille est de 7,29, et de 13, 71 sur la globalité des prédictions). C'est donc celui que nous choisirions dans un cas réel.
"""